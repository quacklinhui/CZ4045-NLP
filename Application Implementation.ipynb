{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import json\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randrange\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenise all the words with the help of a tokeniser\n",
    "# for model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer() #num_words is the tokeniser that fits the number of words\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D #find out how come they using different types of drop outs\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use trained model to get sentiment\n",
    "def predict_sentiment(text): #note that 1 denotes positive and 0 denotes negative\n",
    "    model = keras.models.load_model('model')\n",
    "    tw = tokenizer.texts_to_sequences([text])\n",
    "    tw = pad_sequences(tw,maxlen=200)\n",
    "    prediction = int(model.predict(tw).round().item())\n",
    "    if prediction == 0:\n",
    "        return \"good\"\n",
    "    else:\n",
    "        return \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000299AECDD708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(\"great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Search\n",
    "\n",
    "Search for reviews based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviewSelected100.json') as f:\n",
    "    data = json.loads(\"[\" + \n",
    "        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "    \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses: 153\n"
     ]
    }
   ],
   "source": [
    "unique_businesses = set()\n",
    "for review in data:\n",
    "    unique_businesses.add(review['business_id'])\n",
    "print(\"Number of businesses: \" + str(len(unique_businesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(HOST=\"http://localhost\", PORT=9200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define body of index\n",
    "body={\n",
    "    'settings': {\n",
    "        'number_of_shards': 1,\n",
    "        'number_of_replicas': 0,\n",
    "        'index': {\n",
    "          'sort.field': 'date',\n",
    "          'sort.order': 'asc'\n",
    "        },\n",
    "\n",
    "        # custom analyzer\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                'review_analyzer': {\n",
    "                    'type': 'custom',\n",
    "                      'tokenizer': 'standard',\n",
    "                      'filter': ['lowercase', 'english_stop', 'porter_stem']\n",
    "                    }\n",
    "                  },\n",
    "            'filter': {\n",
    "                'english_stop': { \n",
    "                'type': 'stop',\n",
    "                'stopwords': '_english_'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'text': {\n",
    "                'type': 'text',\n",
    "                'analyzer': 'review_analyzer',\n",
    "                'search_analyzer': 'review_analyzer'\n",
    "            },\n",
    "            'date': {\n",
    "                'type': 'date',\n",
    "                'format': 'yyyy-MM-dd HH:mm:ss'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_generator(data):\n",
    "    for review in data:\n",
    "        yield {\n",
    "                \"_index\": index_name,\n",
    "                \"_type\": \"_doc\",\n",
    "                \"_id\" : f\"{review['review_id']}\",\n",
    "                \"_source\": review,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "ConnectionError(<urllib3.connection.HTTPConnection object at 0x00000299BCCA6588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x00000299BCCA6588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 159\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    251\u001b[0m             response = self.pool.urlopen(\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 168\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000299BCCA6588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d8689c9e0438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"review-index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index created\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\client\\utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\client\\indices.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(self, index, params, headers)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         return self.transport.perform_request(\n\u001b[1;32m--> 350\u001b[1;33m             \u001b[1;34m\"HEAD\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_make_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# Before we make the actual API call we verify the Elasticsearch instance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verified_elasticsearch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_verify_elasticsearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;31m# If '_verified_elasticsearch' isn't 'True' then we raise an error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36m_do_verify_elasticsearch\u001b[1;34m(self, headers, timeout)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# anywhere then we re-raise the more appropriate error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minfo_response\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;31m# Check the information we got back from the index request.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\transport.py\u001b[0m in \u001b[0;36m_do_verify_elasticsearch\u001b[1;34m(self, headers, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m                     _, info_headers, info_response = conn.perform_request(\n\u001b[1;32m--> 562\u001b[1;33m                         \u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m                     )\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[1;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TIMEOUT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N/A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# raise warnings if any from the 'Warnings' header.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ConnectionError(<urllib3.connection.HTTPConnection object at 0x00000299BCCA6588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it) caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x00000299BCCA6588>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it)"
     ]
    }
   ],
   "source": [
    "index_name = \"review-index\"\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=body)\n",
    "    helpers.bulk(es, review_generator(data))\n",
    "    print(\"Index created\")\n",
    "else:\n",
    "    print(\"Index already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveUniqueReviewsByInput(userInput, es, index_name):\n",
    "    doc_count = 0\n",
    "    reviews = []\n",
    "    query = {\n",
    "        \"size\": 100,\n",
    "        \"query\": {\n",
    "            \"query_string\": {\n",
    "                \"query\": userInput\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Make a search request\n",
    "    res = es.search(index=index_name, body=query, scroll='2s')\n",
    "    \n",
    "    for doc in res['hits']['hits']:\n",
    "        doc_count += 1\n",
    "        reviews.append(doc['_source'])\n",
    "    \n",
    "    old_scroll_id = res['_scroll_id']\n",
    "    \n",
    "    while len(res['hits']['hits']):\n",
    "        res = es.scroll(scroll_id=old_scroll_id, scroll='2s')\n",
    "        old_scroll_id = res['_scroll_id']\n",
    "        \n",
    "        # Iterate over hits for each scroll\n",
    "        for doc in res['hits']['hits']:\n",
    "            doc_count += 1\n",
    "            reviews.append(doc['_source'])\n",
    "            \n",
    "    # From the reviews retrieved, extract X reviews, one from each unique business\n",
    "    unique_reviews = []\n",
    "    business_set = set()\n",
    "    count = 0\n",
    "    while count < len(reviews) :\n",
    "        # Don't take review if same business already taken\n",
    "        if reviews[count]['business_id'] in business_set:\n",
    "            count+=1\n",
    "            continue\n",
    "        else:\n",
    "            business_set.add(reviews[count]['business_id'])\n",
    "            unique_reviews.append(reviews[count]) \n",
    "            count+=1\n",
    "    return unique_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveBusinessReviews(businessID, es, index_name):\n",
    "    doc_count = 0\n",
    "    reviews = []\n",
    "    query = {\n",
    "        \"size\": 100,\n",
    "        \"query\": {\n",
    "            \"query_string\": {\n",
    "                \"query\": businessID\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Make a search request\n",
    "    res = es.search(index=index_name, body=query, scroll='2s')\n",
    "    \n",
    "    for doc in res['hits']['hits']:\n",
    "        doc_count += 1\n",
    "        reviews.append(doc['_source']['text'])\n",
    "    \n",
    "    old_scroll_id = res['_scroll_id']\n",
    "    \n",
    "    while len(res['hits']['hits']):\n",
    "        res = es.scroll(scroll_id=old_scroll_id, scroll='2s')\n",
    "        old_scroll_id = res['_scroll_id']\n",
    "\n",
    "        # Iterate over hits for each scroll\n",
    "        for doc in res['hits']['hits']:\n",
    "            doc_count += 1\n",
    "            reviews.append(doc['_source']['text'])\n",
    "        \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    user_input = input(\"Search:\")\n",
    "    \n",
    "    # Get the reviews\n",
    "    reviews_input = retrieveUniqueReviewsByInput(user_input, es, index_name)\n",
    "\n",
    "    # get all business id with particular word\n",
    "    business_id = []\n",
    "    for i in range(len(reviews_input)):\n",
    "        business_id.append(reviews_input[i]['business_id'])\n",
    "    \n",
    "    #get reviews of business with particular word\n",
    "    reviews_by_business = []\n",
    "    for i in range(len(business_id)):\n",
    "        if (business_id[i][0] != '-'):\n",
    "            businessreview = retrieveBusinessReviews(business_id[i], es, index_name)\n",
    "        else:\n",
    "            businessreview = retrieveBusinessReviews(business_id[i][1:], es, index_name)\n",
    "        reviews_by_business.append(businessreview) \n",
    "    reviews_by_business_test = [[\"I usually don't waste my time with chain restaurants, but I've heard a lot of raves about Dunkin' Donuts coffee- when this location sprung up near me, I hurried over to try it. And was distinctly underwhelmed. \\n\\nI was surprised by the variety of the menu, though- in addition to iced and hot coffee drinks, the menu includes the namesake donuts, and various breakfast sandwiches. They have an order of oatmeal available as their lone healthy option.\\n\\nThis location does have a drive-thru, which is convenient. Service was a bit spotty, which is to be expected as they are new. Prices are on par with other coffee chains. Avoid the latte lites, which are straight-up aspartame.\",\n",
    "  'I stopped by this new Dunkin on my way to work this morning and ended up waiting to order a coffee in the drive-thru for a solid TEN minutes and there was no one in front of me. I understand they are new and probably trying to work the kinks out, but ten minutes to order an iced latte seems really excessive. On top of that, the latte I ordered had no flavor to it. I hope they improve their drive-thru time and drinks as this place is easily accessible and usually delicious!',\n",
    "  'Went here 4 days in a row around 8:30 AM.\\n\\nDay 1: Ordered the #1 (2 donuts & a coffee) & the lady manager rings up my debit card & hands it back to me. Asks me what donuts I want all the while chatting/splitting her attention w/ the old guy that looks like he is a regular, daily customer.\\n\\nI finally get a chance to tell her & she tells me the ones I want are 40 cents extra each. I don\\'t mind paying extra but she should have let me tell her what I wanted before swiping my card & handing it back to me. (The two donuts at 40 cents extra equals the total price of the #1 as stated on the menu so I\\'m not really paying \"extra\" rather saving 80 cents if I get 2 regular donuts)\\n\\nDay 2: Ordered the #1 again. Girl at counter asks the guy manager if all the donuts costs the same for the #1 & he says yes. I am happy with my donuts, coffee, & the service so I order 50 donut holes to go for my coworkers.\\n\\nDay 3: Ordered the #1 again but went through the drive thru this time. The guy says he is the seasoned manager & asks me what I would like on my \"ICED\" coffee. I told him I would like 8 Splendas (2 per every 8 ounces plus an extra 1-2 due to the ice)... When I get to the window, he hands me s \"HOT\" coffee (16 oz) & I am already late to work so I just take it & leave. Putting 8 Splendas in 16 oz of hot coffee makes it way too sweet. The coffee sizes differ based on hot or cold (ie: a medium hot coffee is 16 oz while a medium cold iced coffee is 24 oz)\\n\\nDay 4: Decide to give this place one last chance. I order the #1 again & the young girl at the counter asks her manager if all the donuts are the same price to which he tells her that some are 40 cents extra. I had to repeat myself about what I wanted in my coffee but she looked stressed out so I just gave her a break.\\n\\nWhile waiting for my coffee, the two senior citizens in front of me were complaining about their coffee to the manager. The young girl left the register to help with the coffee for the different customers & mixed up some of them. After finally getting my coffe, I left.\\n\\nAll in all, donuts tasted great but their communication & service needs some work. I would still visit this location again but I would make sure to be extremely specific so they do not mess up anything.'],\n",
    " [\"2.5/5, +.5 for service\\n\\nThe long anticipated stall that used to be Toro Sushi has finally opened. After passing by this place at least 10 times a week, I finally saw the open sign lit on Tuesday. Since I was busy yesterday, I decided to wait until tonight to eat here. For 9pm, this place was ridiculously busy. However I assume it was full of people who wanted to try this place for the first time, so I'm not expecting the full seated load to last. \\n\\nThe menu here is very extensive. There was your typical HK style cafe options, as well as dim sum. There are two featured items on the menu which are also advertised outside the restaurant along the wall facing Highway 7. I decided to try one of them, which was the Shanghai style beef noodle soup (forgot the exact term).\\n\\nAs we were waiting for our food, one of the employees gave us two 10% off cards, which are valid until January 31, 2015. The meal itself was also 10% off for their grand opening special.\\n\\nThe food took a good 15-20 minutes to come, however the iced lemon and iced milk teas both came rather quick. The milk tea here seems to be better than the lemon tea, as my dad found the milk tea to be good and I found the lemon tea to be mediocre. As for the noodle soup...it was also mediocre. Edible at least, but definitely not what I would say memorable.\\n\\nThere are a lot of other items in the menu that could be worth trying, but I'm gonna wait for other Yelpers to review this restaurant before considering coming back.\",\n",
    "  \"So what does the newly opened Kitchen M offer up?\\nThe short answer - its a Hong Kong style cafe\\nIt was pretty busy on a Thursday afternoon but I'm guessing its because people are curious to find out what they serve here just like me. Service was blazing fast and we got our food within 5 minutes at the most from ordering. \\n\\nGrouper with spaghetti noodles and cream sauce $10.95 - includes vegetable soup and choice of HK style milk tea or coffee. Everything tasted good but nothing that will WOW you. Also, portions were huge so come on an empty stomach.\\n\\nMalaysian curry and chicken with rice $11.95 - once again includes vegetable soup and choice of hot drink. Found that the chicken was a bit tough and once again portions were huge.\\n\\nOn the back of the menu there is a build your noodle section so you can choose the type of noodles and select two meats to be added. Surprisingly you can't choose the type of soup. It was just your standard chicken broth type of soup. Went with the vermicelli noodles with pig intestine and fish skin, plus you also get a hot drink with it for $8.45. The portions were once again very large and the meal was good but nothing really memorable.\\n\\nIf you are looking for a quick meal that is cheap and filling then this is the place for you.\",\n",
    "  \"Braised beef noodle failed as they use instant udon noodles, hate the after taste. 2 stars. \\n\\nAlso had sirloin steak spaghetti, steak is marinated Hk style so it doesn't quite taste like beef anymore, but ok it's tasty. 3.5 stars. \\n\\nGrouper spaghetti... It's ok. 3.5 stars. \\n\\nMilk tea is actually quite decent.\"],\n",
    " [\"This is a pretty chill bar. Lots of seating and flat screen TVs to watch sports and lounge about. The music is Top 40s and is not loud, so you can easily carry conversations with good friends and have a great time. It is not, however, a place to mingle, hook up, or dance. It's simply not that type of vibe. But it is a good place to meet up friends before you out for the night to debauchery and randomness that is Vegas.\",\n",
    "  \"This place just has a really cool vibe.  It can get crowded, and when it does, it seems to be even more fun.  The hot bartenders getting up and dancing on the bar are a favorite part of it for my wife and I.  The drinks are reasonable for Vegas. When busy service can be a bit slow, but we just can't not spend a little time here whenever we're at the MGM, which is pretty frequently.\",\n",
    "  \"Small... but I like it a lot!\\n\\nCentrifuge sits on the casino floor right across from the entrance to Studio 54.  Pretty good location and at least for the duration I was there (weekday), the crowd was a mixed crowd with young and old.  They have nice booths and tables you can sit at and if you can get a table or a booth, it's a great place to people watch, either at the people in the bar or people out at the casino floors.  Vegas never fails to produce some interesting people haha.\\n\\nBartenders here are great.  Talkative, nice, and make fairly strong drinks.  Prices are average for Vegas, which is nothing to be surprised about.  They have about 5 beers on tap with a nice selection for the bottles.  One bartender even gave us a beer each on the house even though we've only been sitting there chilling with our beer.  Needless to say we gave him a nice tip in the end.  \\n\\nOne fun thing is that when certain songs are played, all the bartenders and wait staff will get up on the bar table and dance.  Even though they aren't that great, it's entertaining nonetheless!\\n\\nThis place is pretty ideal on a weekday to chill after work, and I'm sure on the weekends it can be much more packed.\"]]\n",
    "        \n",
    "    business_id_test = ['0kPm1zEpeXFRg8D2phqgCQ', 'spDZkD6cp0JUUm6ghIWHzA','XGaa9NDCwOJ9v0Cj55p28w']\n",
    "    sentiment_ratio = []\n",
    "    for i in range(len(reviews_by_business_test)):\n",
    "        good_count = 0\n",
    "        bad_count = 0\n",
    "        for j in range(len(reviews_by_business_test[i])):\n",
    "            review = reviews_by_business_test[i][j]\n",
    "            sentiment = predict_sentiment(review)\n",
    "            if sentiment == \"good\":\n",
    "                good_count +=1\n",
    "            if sentiment == \"bad\":\n",
    "                bad_count +=1\n",
    "        if bad_count != 0:\n",
    "            ratio = (good_count/bad_count) / (good_count+bad_count)\n",
    "        else:\n",
    "            ratio = 1\n",
    "        print(good_count)\n",
    "        print(bad_count)\n",
    "        sentiment_ratio.append(ratio)\n",
    "    sentiment_ratio = [2,3,1]\n",
    "    business_sentiment = dict(zip(business_id_test, sentiment_ratio))\n",
    "    sorted_sentiment = sorted(business_sentiment.items(), key=lambda t: t[::-1],reverse=True)\n",
    "    print(sorted_sentiment)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = predict_sentiment('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
