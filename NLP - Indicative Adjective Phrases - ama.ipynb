{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20d83a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc1959",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7ea7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviewSelected100.json') as f:\n",
    "    data = json.loads(\"[\" + \n",
    "        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "    \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fcf64a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses: 153\n"
     ]
    }
   ],
   "source": [
    "# Create a set of all businesses\n",
    "business_set = set()\n",
    "for review in data:\n",
    "    business_set.add(review['business_id'])\n",
    "print(\"Number of businesses: \" + str(len(business_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0dc39",
   "metadata": {},
   "source": [
    "## Finding the Adjective Phrases of a Randomly Selected Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c00b3",
   "metadata": {},
   "source": [
    "Choose a random business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "590d12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_set = list(business_set)\n",
    "selected_business_id = business_set[random.randrange(len(business_set))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "504e5775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p6FPcgLymnpk_gAyQuW_Mw'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_business_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5673ca",
   "metadata": {},
   "source": [
    "Extract out the adjective phrases from all the reviews belonging to this business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b607c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the reviews of the business\n",
    "selected_business_reviews = []\n",
    "for review in data:\n",
    "    if review['business_id'] == selected_business_id:\n",
    "        selected_business_reviews.append(review['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dddc4",
   "metadata": {},
   "source": [
    "Define the grammar rules for the structure of Adjective Phrases (ADJP), as well as other phrase types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a150d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final\n",
    "grammar = ('''\n",
    "    VP: { <TO> <VB> <PRP> <VB.?> | <TO> <VB> <VB.?>? <DT>? <JJ.?>? <NN.?>? }\n",
    "    NC: { <IN>? ((<PRP.>|<DT>) <NN.?> <JJ.?>? <MD> <VB.?>) | <IN>? ((<DT>|<PRP.>) <JJ.?>? <NN.?> <VB.?> (<NN.?>|<VB.>)) | <IN>? <PRP> <VB.?> (<DT>|<PRP.?>) <NN.?> }\n",
    "    PP: { (<IN> <DT>? <JJ.?>? <NN.?>) }\n",
    "    ADJP: { (<IN> <DT>? <NN.?>) | (<PP> <IN> <NN.?>) | <RB.?>* <JJ.?> <PP> | <RB.?>* <JJ.?> <VP> | <RB.?>* <JJ.?> <NC> | (<RB.?>* <JJ.?> <,>? <CC>?)+ | (<JJ.?> <,>? <CC>?)+ | <JJ.?>* | <RB.?>+ <VB(G|N)> }\n",
    "    ''')\n",
    "\n",
    "# Preposition + noun | PP + noun | (adv) adj + PP | (adv) adj + VP | (adv) adj + NC | Adverb Adjective(s) | Adjective chain(s) | Adjective(s) | Some VBG/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d860aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkParser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fba0b",
   "metadata": {},
   "source": [
    "Parse each review, analysing its phrase structure and extracting out only the adjective phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a2dad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_phrases = []\n",
    "\n",
    "for review in selected_business_reviews:\n",
    "    # tokenize and perform pos tagging on each review\n",
    "    tagged_tokens = nltk.pos_tag(nltk.word_tokenize(review))\n",
    "    # parse the review\n",
    "    tree = chunkParser.parse(tagged_tokens)\n",
    "    # go through the parse tree and append adjective phrases (ADJP)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == \"ADJP\":\n",
    "            adjective_phrase = []\n",
    "            for leaf in subtree.leaves():  # each leaf is a tuple (token, pos_tag)\n",
    "                adjective_phrase.append(leaf[0]) # append the token\n",
    "            adjective_phrase = \" \".join(adjective_phrase) # merge the tokens of the phrase\n",
    "            adjective_phrases.append(adjective_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9b55be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome and cheap',\n",
       " 'literal',\n",
       " 'Typical taco',\n",
       " 'awesome , authentic , and',\n",
       " 'go',\n",
       " 'beat',\n",
       " 'much more',\n",
       " 'huge',\n",
       " 'def larger',\n",
       " 'Happy',\n",
       " 'Excellent',\n",
       " 'mexican',\n",
       " 'really good',\n",
       " 'hot',\n",
       " 'u',\n",
       " 'im',\n",
       " 'best',\n",
       " 'open late and',\n",
       " 'desperate',\n",
       " 'final',\n",
       " 'just flinging',\n",
       " 'tiring',\n",
       " 'plastic',\n",
       " 'no longer eating',\n",
       " 'Best',\n",
       " 'able to put',\n",
       " 'really good',\n",
       " 'fast',\n",
       " 'i',\n",
       " 'tacos',\n",
       " 'perfect',\n",
       " 'add',\n",
       " 'single',\n",
       " 'always left',\n",
       " 'happy and',\n",
       " 'top of the line',\n",
       " 'single',\n",
       " 'more',\n",
       " 'hot and fresh',\n",
       " 'wide',\n",
       " 'best',\n",
       " 'Best bodega',\n",
       " 'great',\n",
       " 'fresh',\n",
       " 'great and',\n",
       " 'not only insanely delicious , but',\n",
       " 'most of the time',\n",
       " 'much',\n",
       " 'hefty',\n",
       " 'full ,',\n",
       " 'super',\n",
       " 'great',\n",
       " 'little',\n",
       " 'native',\n",
       " 'best mexican',\n",
       " 'top',\n",
       " 'Very tasty , very clean',\n",
       " 'Generous',\n",
       " 'low',\n",
       " 'great',\n",
       " 'clean and',\n",
       " 'quick',\n",
       " 'busy',\n",
       " 'new regular',\n",
       " 'best',\n",
       " 'other',\n",
       " 'huge',\n",
       " 'fast and friendly',\n",
       " 'huge',\n",
       " 'good',\n",
       " 'finally found',\n",
       " 'late',\n",
       " 'good',\n",
       " 'fish &',\n",
       " 'favorite',\n",
       " 'really just going',\n",
       " 'crazy , and',\n",
       " 'fine and dandy , but',\n",
       " 'super hungry',\n",
       " 'open at this hour',\n",
       " 'best carne',\n",
       " 'ever had',\n",
       " 'Sure ,',\n",
       " 'gracious',\n",
       " 'delicious',\n",
       " 'delicious',\n",
       " 'good',\n",
       " 'Best',\n",
       " 'ever existed',\n",
       " 'mile',\n",
       " 'enough',\n",
       " 'street-style',\n",
       " 'not expensive',\n",
       " 'good',\n",
       " 'quick , cheap and tasty',\n",
       " 'pretty hungry',\n",
       " 'near-ish',\n",
       " 'plentiful',\n",
       " 'late',\n",
       " 'great for late night',\n",
       " 'so friendly and',\n",
       " 'great',\n",
       " 'extraordinary vey impressive',\n",
       " 'hesitant about the sanitation',\n",
       " 'great but',\n",
       " 'american',\n",
       " 'hot and',\n",
       " 'sure',\n",
       " 'decent',\n",
       " 'current',\n",
       " 'leaderless american',\n",
       " 'AMAZING',\n",
       " 'huge ,',\n",
       " 'so fresh and',\n",
       " 'fresh',\n",
       " 'many',\n",
       " 'same',\n",
       " 'different',\n",
       " 'sketchy little',\n",
       " 'right next',\n",
       " 'factor-',\n",
       " 'last',\n",
       " 'favorite Mexican',\n",
       " 'dry',\n",
       " 'good',\n",
       " 'sure and',\n",
       " 'good',\n",
       " 'worst Mexican',\n",
       " 'new late',\n",
       " 'excellent',\n",
       " 'excellent',\n",
       " 'sit-down',\n",
       " 'little',\n",
       " 'cheap but',\n",
       " 'soggy',\n",
       " 'hard to eat',\n",
       " 'very dry',\n",
       " 'Freshly prepared , huge',\n",
       " 'delicious , and',\n",
       " 'available , and',\n",
       " 'really friendly',\n",
       " 'Thursday-Saturday and',\n",
       " 'Sunday-Wednesday',\n",
       " 'very reasonable',\n",
       " '6-7',\n",
       " 'best mexican next',\n",
       " 'Amazing',\n",
       " 'bigger',\n",
       " 'best',\n",
       " 'Best',\n",
       " 'mexican',\n",
       " 'Amazing',\n",
       " 'huge and awesome',\n",
       " 'heavier',\n",
       " 'really good',\n",
       " 'friendly and',\n",
       " 'genuinely appreciative to have',\n",
       " 'super',\n",
       " 'wall',\n",
       " 'best little',\n",
       " 'new favorite',\n",
       " 'financial',\n",
       " 'really good',\n",
       " 'So lucky to have stumbled',\n",
       " 'best',\n",
       " 'available',\n",
       " 'good , quick',\n",
       " 'huge',\n",
       " 'few',\n",
       " 'cold and',\n",
       " 'not cooked',\n",
       " 'nice to add',\n",
       " 'fresh',\n",
       " 'pippin hot',\n",
       " 'delicious',\n",
       " 'little disappointed',\n",
       " 'very small',\n",
       " 'Only',\n",
       " 'better',\n",
       " 'guac',\n",
       " 'perfect',\n",
       " 'amazing',\n",
       " 'Such good',\n",
       " 'awesome cultural',\n",
       " 'Best',\n",
       " 'ever ordered',\n",
       " 'perfectly delivered',\n",
       " 'Wish',\n",
       " 'Best',\n",
       " 'great',\n",
       " 'near',\n",
       " 'mexican',\n",
       " 'favorite',\n",
       " 'mine',\n",
       " 'good',\n",
       " 'sure to let you hear',\n",
       " 'really good',\n",
       " 'Very good',\n",
       " 'Reasonable',\n",
       " 'so little',\n",
       " 'hidden',\n",
       " 'so good',\n",
       " 'always impressed',\n",
       " 'fresh',\n",
       " 'here .....',\n",
       " 'always raving',\n",
       " 'awesome',\n",
       " 'particular',\n",
       " 'looked and',\n",
       " 'so good',\n",
       " 'best',\n",
       " 'french',\n",
       " 'green',\n",
       " 'more',\n",
       " 'as GOOD as the first time',\n",
       " 'small',\n",
       " 'hot',\n",
       " 'definite well kept',\n",
       " 'secret',\n",
       " 'very low',\n",
       " 'very casual',\n",
       " 'shot best',\n",
       " 'whole wide',\n",
       " 'so good',\n",
       " 'him/her',\n",
       " 'so legit',\n",
       " 'great reviews',\n",
       " 'fantastic',\n",
       " 'extra hot',\n",
       " 'best',\n",
       " 'amazing',\n",
       " 'great',\n",
       " 'best',\n",
       " 'ever had',\n",
       " 'more',\n",
       " 'curious about the chicken',\n",
       " 'not too salty or greasy',\n",
       " 'perfect',\n",
       " 'so massive and intense',\n",
       " \"n't ever even eat\",\n",
       " 'cheaper',\n",
       " 'soggy',\n",
       " 'delicious',\n",
       " 'nacho-cheesy',\n",
       " 'weird',\n",
       " 'amazing and',\n",
       " 'just like',\n",
       " 'ridiculous',\n",
       " 'super',\n",
       " 'super',\n",
       " 'outside at all hours',\n",
       " 'giant',\n",
       " 'favorite late-night',\n",
       " 'open late',\n",
       " 'Great',\n",
       " 'good',\n",
       " 'always made',\n",
       " 'fresh',\n",
       " 'Busy , but',\n",
       " 'extremely fair',\n",
       " 'huuuge and delicious',\n",
       " 'exceptional',\n",
       " 'very attractive',\n",
       " 'combo',\n",
       " 'assemble',\n",
       " 'perfectly cooked',\n",
       " 'great',\n",
       " 'picnic',\n",
       " 'other',\n",
       " 'fastest and biggest',\n",
       " 'ever had',\n",
       " 'more authentic than mainstream',\n",
       " 'good',\n",
       " 'good and piled',\n",
       " 'good',\n",
       " 'right',\n",
       " 'last',\n",
       " 'outside but',\n",
       " 'cheap',\n",
       " 'awesome',\n",
       " 'great',\n",
       " 'friendly',\n",
       " 'there more than a few times',\n",
       " 'late',\n",
       " 'carne',\n",
       " 'other',\n",
       " \"n't sure\",\n",
       " 'still serving',\n",
       " 'right',\n",
       " 'Well good',\n",
       " 'deep and',\n",
       " 'random',\n",
       " 'friendly and',\n",
       " 'creepy',\n",
       " 'huge',\n",
       " 'next',\n",
       " 'good',\n",
       " 'tonight',\n",
       " 'carne',\n",
       " 'extra super',\n",
       " 'hard',\n",
       " 'ecstatic',\n",
       " 'great',\n",
       " 'always friendly and',\n",
       " 'little too much',\n",
       " 'not so pretty',\n",
       " 'asada',\n",
       " 'usual',\n",
       " 'stop many',\n",
       " 'freshly cut',\n",
       " 'clean',\n",
       " 'legit',\n",
       " 'SO good but',\n",
       " 'secret',\n",
       " 'back',\n",
       " 'humongous in size',\n",
       " 'warm',\n",
       " 'freshly cooked',\n",
       " 'then carefully wrapped',\n",
       " \"n't scolding\",\n",
       " 'hot , but',\n",
       " 'more',\n",
       " 'well seasoned and',\n",
       " 'fantastic',\n",
       " 'relatively cheap for the amount',\n",
       " 'amazing',\n",
       " 'much better',\n",
       " 'great',\n",
       " 'extra for guacamole',\n",
       " 'less expensive',\n",
       " 'actually included',\n",
       " 'high',\n",
       " 'average',\n",
       " 'very popular such',\n",
       " 'hot',\n",
       " 'screams',\n",
       " 'very focused',\n",
       " 'general',\n",
       " 'whole',\n",
       " 'unique , and',\n",
       " 'only',\n",
       " 'better',\n",
       " 'more',\n",
       " 'so good',\n",
       " 'hustle',\n",
       " 'friendly',\n",
       " 'extremely nice',\n",
       " 'very professional and',\n",
       " 'extremely fast for the amount',\n",
       " 'surprisingly organized',\n",
       " 'Walked',\n",
       " 'small and',\n",
       " 'carne',\n",
       " 'carne',\n",
       " 'sour',\n",
       " 'hot green',\n",
       " 'hot red',\n",
       " 'green',\n",
       " 'so good',\n",
       " 'very hot but',\n",
       " 'great',\n",
       " 'decent',\n",
       " 'very good but',\n",
       " 'not shredded',\n",
       " 'perfect',\n",
       " 'good',\n",
       " 'so gross',\n",
       " 'undercooked and',\n",
       " 'so bad',\n",
       " 'first',\n",
       " 'friendly',\n",
       " 'sure but',\n",
       " 'Great',\n",
       " 'Mexican',\n",
       " 'hot',\n",
       " 'not great',\n",
       " 'only',\n",
       " 'sour',\n",
       " 'minimal and',\n",
       " 'wet',\n",
       " 'good',\n",
       " 'sketchy',\n",
       " 'large',\n",
       " 'huge',\n",
       " 'never eaten',\n",
       " 'frat',\n",
       " 'such',\n",
       " 'usual',\n",
       " 'not really mexican',\n",
       " 'still good',\n",
       " 'really cool and',\n",
       " 'ready',\n",
       " 'less',\n",
       " 'other',\n",
       " 'nice',\n",
       " 'not standing',\n",
       " 'outside , but',\n",
       " 'legit',\n",
       " 'here everyday',\n",
       " 'more',\n",
       " 'fresh daily',\n",
       " 'great',\n",
       " 'Large',\n",
       " 'best',\n",
       " 'best',\n",
       " 'outstanding',\n",
       " 'other',\n",
       " 'late',\n",
       " 'awesome',\n",
       " 'best and most authentic Mexican',\n",
       " 'lucky',\n",
       " 'extremely clean and',\n",
       " 'large',\n",
       " 'best Mexican',\n",
       " 'always awesome',\n",
       " 'best',\n",
       " 'nice and',\n",
       " 'good',\n",
       " 'good',\n",
       " 'super',\n",
       " 'real',\n",
       " 'away little',\n",
       " 'pretty packed',\n",
       " 'pretty good',\n",
       " 'best but',\n",
       " 'spiritual',\n",
       " 'other',\n",
       " 'always open and',\n",
       " 'Mexican',\n",
       " 'good',\n",
       " 'great late',\n",
       " 'Good',\n",
       " 'nachos and',\n",
       " 'able to add',\n",
       " 'good',\n",
       " 'good and',\n",
       " 'just spicy',\n",
       " 'really good',\n",
       " 'more',\n",
       " 'not super',\n",
       " 'nachos',\n",
       " 'hungry',\n",
       " 'great',\n",
       " 'Literal',\n",
       " 'full of fresh ingredients',\n",
       " 'Huge',\n",
       " 'favorite',\n",
       " 'amazing and',\n",
       " 'awesome',\n",
       " 'Very good',\n",
       " 'short',\n",
       " 'best',\n",
       " 'not greasy or frozen',\n",
       " 'fresh and right',\n",
       " 'red',\n",
       " 'helpful',\n",
       " 'only',\n",
       " 'more',\n",
       " 'only',\n",
       " 'right',\n",
       " 'double',\n",
       " 'many',\n",
       " 'Great',\n",
       " 'great',\n",
       " 'great quick',\n",
       " 'fireball',\n",
       " 'best',\n",
       " 'Friendly',\n",
       " 'best Mexican',\n",
       " 'least',\n",
       " 'delicious',\n",
       " 'brass',\n",
       " 'digital',\n",
       " 'ever dreamed',\n",
       " 'top',\n",
       " 'many',\n",
       " 'double',\n",
       " 'single',\n",
       " 'worst',\n",
       " 'ever made',\n",
       " 'good',\n",
       " 'fine',\n",
       " 'very few',\n",
       " 'fancy little chic',\n",
       " 'somehow rated',\n",
       " 'best',\n",
       " 'best',\n",
       " 'single',\n",
       " 'most of the food',\n",
       " \"n't very memorable , but\",\n",
       " 'massive',\n",
       " 'open',\n",
       " 'more gangster',\n",
       " 'ever done',\n",
       " 'fish and',\n",
       " 'French',\n",
       " 'cheap and nasty and',\n",
       " 'possible to screw',\n",
       " 'basic',\n",
       " 'dish such',\n",
       " 'fish and',\n",
       " 'bread',\n",
       " 'literal',\n",
       " 'freshman',\n",
       " 'best Mexican',\n",
       " 'great',\n",
       " 'new',\n",
       " 'clean ,',\n",
       " 'super nice and',\n",
       " 'carne',\n",
       " 'free friendly',\n",
       " 'easy to sub anything',\n",
       " 'iffy',\n",
       " 'only seen',\n",
       " 'ASU',\n",
       " 'same',\n",
       " 'happily doing',\n",
       " 'okay',\n",
       " 'real Mexican',\n",
       " 'more',\n",
       " 'more professional',\n",
       " 'speak',\n",
       " 'open in the late nights',\n",
       " 'always welcoming',\n",
       " 'little disappointed',\n",
       " \"n't expecting\",\n",
       " 'ground',\n",
       " 'next',\n",
       " 'little',\n",
       " 'not just picked',\n",
       " 'el',\n",
       " 'always been',\n",
       " 'good but',\n",
       " 'still getting',\n",
       " 'extremely nice',\n",
       " 'only',\n",
       " 'too hot',\n",
       " 'hot',\n",
       " 'bad',\n",
       " 'mixed',\n",
       " 'fresh , but',\n",
       " 'hidden',\n",
       " 'quality fast mexican',\n",
       " 'chicken',\n",
       " 'great for late night',\n",
       " 'Good',\n",
       " 'very good',\n",
       " 'absolute best',\n",
       " 'ever had',\n",
       " 'Best',\n",
       " 'as big',\n",
       " 'tiny little',\n",
       " 'outside',\n",
       " 'pleasant',\n",
       " 'cramped',\n",
       " 'very tidy and',\n",
       " 'also pleasantly surprised',\n",
       " 'good',\n",
       " 'such',\n",
       " 'small',\n",
       " 'greasy gustatory',\n",
       " 'American',\n",
       " 'chicken',\n",
       " 'regular',\n",
       " 'few',\n",
       " 'different',\n",
       " 'sour',\n",
       " 'mega',\n",
       " 'curious',\n",
       " 'pretty good',\n",
       " 'so much',\n",
       " 'soggy',\n",
       " 'soggier over time',\n",
       " 'nice and fluffy and',\n",
       " 'very generous',\n",
       " 'other nice',\n",
       " 'open',\n",
       " 'late',\n",
       " 'so sick',\n",
       " 'next',\n",
       " 'soggy',\n",
       " 'hard to eat',\n",
       " 'very dry',\n",
       " 'awesome , open',\n",
       " 'big',\n",
       " 'cool ,']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjective_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0456ee59",
   "metadata": {},
   "source": [
    "### Now, we need to determine which adjective phrases are indicative\n",
    "We perform TD-IDF in order to determine which phrases are unique to the business\n",
    "- Find the TF of each adjective phrase\n",
    "- Create a biword/inverted index (TBC) to store the Document Frequency of each biword/term\n",
    "- Compute the TF-IDF of each adjective phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d871a",
   "metadata": {},
   "source": [
    "First, preprocess the entire dataset before performing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0a27c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all the text\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "894d66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numerical values\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i for i in text if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f8da9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence tokenizer\n",
    "def sentence_tokenize(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d1f2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations\n",
    "def remove_punctuation(sentences):\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        result.append(sentence.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45f7c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences -> words\n",
    "def tokenize(sentences):\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        result.append(word_tokenize(sentence))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d29b5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "def remove_stopwords(sentences):\n",
    "    result = []\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    for sentence in sentences:\n",
    "        filtered = []\n",
    "        for word in sentence:\n",
    "            if word not in stopwords:\n",
    "                filtered.append(word)\n",
    "        result.append(filtered)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b439242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "def stemming(sentences): #text is an array of strings\n",
    "    result = []\n",
    "    ps = PorterStemmer()\n",
    "    for sentence in sentences:\n",
    "        result.append([ps.stem(word) for word in sentence])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ce3ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocess(text):\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = sentence_tokenize(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = stemming(text)\n",
    "    return text\n",
    "# Outputs a list of lists containing tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48207b",
   "metadata": {},
   "source": [
    "Create biword/uniword index: Dictionary with bigram/word as the key and the value being the set of businesses that contain that bigram/word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46406bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams given an array of arrays of strings\n",
    "def generate_bigrams(sentences):\n",
    "    bigrams = []\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            bigrams.append((sentence[i], sentence[i+1]))\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73b973fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index\n",
    "index = {}\n",
    "for review in data:\n",
    "    b_id = review['business_id']\n",
    "    preprocessed_text = preprocess(review['text']) # Array of arrays of tokens\n",
    "    bigrams = generate_bigrams(preprocessed_text)\n",
    "    \n",
    "    # index the unigrams\n",
    "    for sentence in preprocessed_text:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                index[word].add(b_id)\n",
    "            except:\n",
    "                index[word] = {b_id}\n",
    "    # index the bigrams\n",
    "    for bigram in bigrams:\n",
    "        try:\n",
    "            index[bigram].add(b_id)\n",
    "        except:\n",
    "            index[bigram] = {b_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86f51b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we don't need to list of business ids in the index, we convert it to the count of business ids\n",
    "for key in index:\n",
    "    index[key] = len(index[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fc738",
   "metadata": {},
   "source": [
    "#### Calculating TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33621e24",
   "metadata": {},
   "source": [
    "###### Term Frequency\n",
    "Term frequency is calculated by number of occurrences of the term divided by the number of terms in the entire document (in this case, the business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bfb49550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find word count\n",
    "word_count = 0\n",
    "for review in data:\n",
    "    if review['business_id'] == selected_business_id:\n",
    "        for sentence in preprocess(review['text']):\n",
    "            word_count += len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "588e5084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3747"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2744369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bigram count\n",
    "bigram_count = 0\n",
    "for review in data:\n",
    "    if review['business_id'] == selected_business_id:\n",
    "        sentences = preprocess(review['text'])\n",
    "        bigrams = generate_bigrams(sentences)\n",
    "        bigram_count += len(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6f1b589b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3173"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aedf4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the TF\n",
    "def computeTF(wordDict, bagOfWords, hasAdjPhrases):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        if hasAdjPhrases == True:\n",
    "            tfDict[word] = count / float(bagOfWordsCount)\n",
    "        else:\n",
    "            tfDict[word] = count / 1\n",
    "    return tfDict\n",
    "\n",
    "def find_ngram_count(ngram, business_id, data):\n",
    "    if len(ngram) == 1:\n",
    "        \n",
    "    else:\n",
    "        \n",
    "\n",
    "def computeTF(ngram, total_count):\n",
    "    return ngram / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c57328e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome and cheap',\n",
       " 'literal',\n",
       " 'Typical taco',\n",
       " 'awesome , authentic , and',\n",
       " 'go',\n",
       " 'beat',\n",
       " 'much more',\n",
       " 'huge',\n",
       " 'def larger',\n",
       " 'Happy',\n",
       " 'Excellent',\n",
       " 'mexican',\n",
       " 'really good',\n",
       " 'hot',\n",
       " 'u',\n",
       " 'im',\n",
       " 'best',\n",
       " 'open late and',\n",
       " 'desperate',\n",
       " 'final',\n",
       " 'just flinging',\n",
       " 'tiring',\n",
       " 'plastic',\n",
       " 'no longer eating',\n",
       " 'Best',\n",
       " 'able to put',\n",
       " 'really good',\n",
       " 'fast',\n",
       " 'i',\n",
       " 'tacos',\n",
       " 'perfect',\n",
       " 'add',\n",
       " 'single',\n",
       " 'always left',\n",
       " 'happy and',\n",
       " 'top of the line',\n",
       " 'single',\n",
       " 'more',\n",
       " 'hot and fresh',\n",
       " 'wide',\n",
       " 'best',\n",
       " 'Best bodega',\n",
       " 'great',\n",
       " 'fresh',\n",
       " 'great and',\n",
       " 'not only insanely delicious , but',\n",
       " 'most of the time',\n",
       " 'much',\n",
       " 'hefty',\n",
       " 'full ,',\n",
       " 'super',\n",
       " 'great',\n",
       " 'little',\n",
       " 'native',\n",
       " 'best mexican',\n",
       " 'top',\n",
       " 'Very tasty , very clean',\n",
       " 'Generous',\n",
       " 'low',\n",
       " 'great',\n",
       " 'clean and',\n",
       " 'quick',\n",
       " 'busy',\n",
       " 'new regular',\n",
       " 'best',\n",
       " 'other',\n",
       " 'huge',\n",
       " 'fast and friendly',\n",
       " 'huge',\n",
       " 'good',\n",
       " 'finally found',\n",
       " 'late',\n",
       " 'good',\n",
       " 'fish &',\n",
       " 'favorite',\n",
       " 'really just going',\n",
       " 'crazy , and',\n",
       " 'fine and dandy , but',\n",
       " 'super hungry',\n",
       " 'open at this hour',\n",
       " 'best carne',\n",
       " 'ever had',\n",
       " 'Sure ,',\n",
       " 'gracious',\n",
       " 'delicious',\n",
       " 'delicious',\n",
       " 'good',\n",
       " 'Best',\n",
       " 'ever existed',\n",
       " 'mile',\n",
       " 'enough',\n",
       " 'street-style',\n",
       " 'not expensive',\n",
       " 'good',\n",
       " 'quick , cheap and tasty',\n",
       " 'pretty hungry',\n",
       " 'near-ish',\n",
       " 'plentiful',\n",
       " 'late',\n",
       " 'great for late night',\n",
       " 'so friendly and',\n",
       " 'great',\n",
       " 'extraordinary vey impressive',\n",
       " 'hesitant about the sanitation',\n",
       " 'great but',\n",
       " 'american',\n",
       " 'hot and',\n",
       " 'sure',\n",
       " 'decent',\n",
       " 'current',\n",
       " 'leaderless american',\n",
       " 'AMAZING',\n",
       " 'huge ,',\n",
       " 'so fresh and',\n",
       " 'fresh',\n",
       " 'many',\n",
       " 'same',\n",
       " 'different',\n",
       " 'sketchy little',\n",
       " 'right next',\n",
       " 'factor-',\n",
       " 'last',\n",
       " 'favorite Mexican',\n",
       " 'dry',\n",
       " 'good',\n",
       " 'sure and',\n",
       " 'good',\n",
       " 'worst Mexican',\n",
       " 'new late',\n",
       " 'excellent',\n",
       " 'excellent',\n",
       " 'sit-down',\n",
       " 'little',\n",
       " 'cheap but',\n",
       " 'soggy',\n",
       " 'hard to eat',\n",
       " 'very dry',\n",
       " 'Freshly prepared , huge',\n",
       " 'delicious , and',\n",
       " 'available , and',\n",
       " 'really friendly',\n",
       " 'Thursday-Saturday and',\n",
       " 'Sunday-Wednesday',\n",
       " 'very reasonable',\n",
       " '6-7',\n",
       " 'best mexican next',\n",
       " 'Amazing',\n",
       " 'bigger',\n",
       " 'best',\n",
       " 'Best',\n",
       " 'mexican',\n",
       " 'Amazing',\n",
       " 'huge and awesome',\n",
       " 'heavier',\n",
       " 'really good',\n",
       " 'friendly and',\n",
       " 'genuinely appreciative to have',\n",
       " 'super',\n",
       " 'wall',\n",
       " 'best little',\n",
       " 'new favorite',\n",
       " 'financial',\n",
       " 'really good',\n",
       " 'So lucky to have stumbled',\n",
       " 'best',\n",
       " 'available',\n",
       " 'good , quick',\n",
       " 'huge',\n",
       " 'few',\n",
       " 'cold and',\n",
       " 'not cooked',\n",
       " 'nice to add',\n",
       " 'fresh',\n",
       " 'pippin hot',\n",
       " 'delicious',\n",
       " 'little disappointed',\n",
       " 'very small',\n",
       " 'Only',\n",
       " 'better',\n",
       " 'guac',\n",
       " 'perfect',\n",
       " 'amazing',\n",
       " 'Such good',\n",
       " 'awesome cultural',\n",
       " 'Best',\n",
       " 'ever ordered',\n",
       " 'perfectly delivered',\n",
       " 'Wish',\n",
       " 'Best',\n",
       " 'great',\n",
       " 'near',\n",
       " 'mexican',\n",
       " 'favorite',\n",
       " 'mine',\n",
       " 'good',\n",
       " 'sure to let you hear',\n",
       " 'really good',\n",
       " 'Very good',\n",
       " 'Reasonable',\n",
       " 'so little',\n",
       " 'hidden',\n",
       " 'so good',\n",
       " 'always impressed',\n",
       " 'fresh',\n",
       " 'here .....',\n",
       " 'always raving',\n",
       " 'awesome',\n",
       " 'particular',\n",
       " 'looked and',\n",
       " 'so good',\n",
       " 'best',\n",
       " 'french',\n",
       " 'green',\n",
       " 'more',\n",
       " 'as GOOD as the first time',\n",
       " 'small',\n",
       " 'hot',\n",
       " 'definite well kept',\n",
       " 'secret',\n",
       " 'very low',\n",
       " 'very casual',\n",
       " 'shot best',\n",
       " 'whole wide',\n",
       " 'so good',\n",
       " 'him/her',\n",
       " 'so legit',\n",
       " 'great reviews',\n",
       " 'fantastic',\n",
       " 'extra hot',\n",
       " 'best',\n",
       " 'amazing',\n",
       " 'great',\n",
       " 'best',\n",
       " 'ever had',\n",
       " 'more',\n",
       " 'curious about the chicken',\n",
       " 'not too salty or greasy',\n",
       " 'perfect',\n",
       " 'so massive and intense',\n",
       " \"n't ever even eat\",\n",
       " 'cheaper',\n",
       " 'soggy',\n",
       " 'delicious',\n",
       " 'nacho-cheesy',\n",
       " 'weird',\n",
       " 'amazing and',\n",
       " 'just like',\n",
       " 'ridiculous',\n",
       " 'super',\n",
       " 'super',\n",
       " 'outside at all hours',\n",
       " 'giant',\n",
       " 'favorite late-night',\n",
       " 'open late',\n",
       " 'Great',\n",
       " 'good',\n",
       " 'always made',\n",
       " 'fresh',\n",
       " 'Busy , but',\n",
       " 'extremely fair',\n",
       " 'huuuge and delicious',\n",
       " 'exceptional',\n",
       " 'very attractive',\n",
       " 'combo',\n",
       " 'assemble',\n",
       " 'perfectly cooked',\n",
       " 'great',\n",
       " 'picnic',\n",
       " 'other',\n",
       " 'fastest and biggest',\n",
       " 'ever had',\n",
       " 'more authentic than mainstream',\n",
       " 'good',\n",
       " 'good and piled',\n",
       " 'good',\n",
       " 'right',\n",
       " 'last',\n",
       " 'outside but',\n",
       " 'cheap',\n",
       " 'awesome',\n",
       " 'great',\n",
       " 'friendly',\n",
       " 'there more than a few times',\n",
       " 'late',\n",
       " 'carne',\n",
       " 'other',\n",
       " \"n't sure\",\n",
       " 'still serving',\n",
       " 'right',\n",
       " 'Well good',\n",
       " 'deep and',\n",
       " 'random',\n",
       " 'friendly and',\n",
       " 'creepy',\n",
       " 'huge',\n",
       " 'next',\n",
       " 'good',\n",
       " 'tonight',\n",
       " 'carne',\n",
       " 'extra super',\n",
       " 'hard',\n",
       " 'ecstatic',\n",
       " 'great',\n",
       " 'always friendly and',\n",
       " 'little too much',\n",
       " 'not so pretty',\n",
       " 'asada',\n",
       " 'usual',\n",
       " 'stop many',\n",
       " 'freshly cut',\n",
       " 'clean',\n",
       " 'legit',\n",
       " 'SO good but',\n",
       " 'secret',\n",
       " 'back',\n",
       " 'humongous in size',\n",
       " 'warm',\n",
       " 'freshly cooked',\n",
       " 'then carefully wrapped',\n",
       " \"n't scolding\",\n",
       " 'hot , but',\n",
       " 'more',\n",
       " 'well seasoned and',\n",
       " 'fantastic',\n",
       " 'relatively cheap for the amount',\n",
       " 'amazing',\n",
       " 'much better',\n",
       " 'great',\n",
       " 'extra for guacamole',\n",
       " 'less expensive',\n",
       " 'actually included',\n",
       " 'high',\n",
       " 'average',\n",
       " 'very popular such',\n",
       " 'hot',\n",
       " 'screams',\n",
       " 'very focused',\n",
       " 'general',\n",
       " 'whole',\n",
       " 'unique , and',\n",
       " 'only',\n",
       " 'better',\n",
       " 'more',\n",
       " 'so good',\n",
       " 'hustle',\n",
       " 'friendly',\n",
       " 'extremely nice',\n",
       " 'very professional and',\n",
       " 'extremely fast for the amount',\n",
       " 'surprisingly organized',\n",
       " 'Walked',\n",
       " 'small and',\n",
       " 'carne',\n",
       " 'carne',\n",
       " 'sour',\n",
       " 'hot green',\n",
       " 'hot red',\n",
       " 'green',\n",
       " 'so good',\n",
       " 'very hot but',\n",
       " 'great',\n",
       " 'decent',\n",
       " 'very good but',\n",
       " 'not shredded',\n",
       " 'perfect',\n",
       " 'good',\n",
       " 'so gross',\n",
       " 'undercooked and',\n",
       " 'so bad',\n",
       " 'first',\n",
       " 'friendly',\n",
       " 'sure but',\n",
       " 'Great',\n",
       " 'Mexican',\n",
       " 'hot',\n",
       " 'not great',\n",
       " 'only',\n",
       " 'sour',\n",
       " 'minimal and',\n",
       " 'wet',\n",
       " 'good',\n",
       " 'sketchy',\n",
       " 'large',\n",
       " 'huge',\n",
       " 'never eaten',\n",
       " 'frat',\n",
       " 'such',\n",
       " 'usual',\n",
       " 'not really mexican',\n",
       " 'still good',\n",
       " 'really cool and',\n",
       " 'ready',\n",
       " 'less',\n",
       " 'other',\n",
       " 'nice',\n",
       " 'not standing',\n",
       " 'outside , but',\n",
       " 'legit',\n",
       " 'here everyday',\n",
       " 'more',\n",
       " 'fresh daily',\n",
       " 'great',\n",
       " 'Large',\n",
       " 'best',\n",
       " 'best',\n",
       " 'outstanding',\n",
       " 'other',\n",
       " 'late',\n",
       " 'awesome',\n",
       " 'best and most authentic Mexican',\n",
       " 'lucky',\n",
       " 'extremely clean and',\n",
       " 'large',\n",
       " 'best Mexican',\n",
       " 'always awesome',\n",
       " 'best',\n",
       " 'nice and',\n",
       " 'good',\n",
       " 'good',\n",
       " 'super',\n",
       " 'real',\n",
       " 'away little',\n",
       " 'pretty packed',\n",
       " 'pretty good',\n",
       " 'best but',\n",
       " 'spiritual',\n",
       " 'other',\n",
       " 'always open and',\n",
       " 'Mexican',\n",
       " 'good',\n",
       " 'great late',\n",
       " 'Good',\n",
       " 'nachos and',\n",
       " 'able to add',\n",
       " 'good',\n",
       " 'good and',\n",
       " 'just spicy',\n",
       " 'really good',\n",
       " 'more',\n",
       " 'not super',\n",
       " 'nachos',\n",
       " 'hungry',\n",
       " 'great',\n",
       " 'Literal',\n",
       " 'full of fresh ingredients',\n",
       " 'Huge',\n",
       " 'favorite',\n",
       " 'amazing and',\n",
       " 'awesome',\n",
       " 'Very good',\n",
       " 'short',\n",
       " 'best',\n",
       " 'not greasy or frozen',\n",
       " 'fresh and right',\n",
       " 'red',\n",
       " 'helpful',\n",
       " 'only',\n",
       " 'more',\n",
       " 'only',\n",
       " 'right',\n",
       " 'double',\n",
       " 'many',\n",
       " 'Great',\n",
       " 'great',\n",
       " 'great quick',\n",
       " 'fireball',\n",
       " 'best',\n",
       " 'Friendly',\n",
       " 'best Mexican',\n",
       " 'least',\n",
       " 'delicious',\n",
       " 'brass',\n",
       " 'digital',\n",
       " 'ever dreamed',\n",
       " 'top',\n",
       " 'many',\n",
       " 'double',\n",
       " 'single',\n",
       " 'worst',\n",
       " 'ever made',\n",
       " 'good',\n",
       " 'fine',\n",
       " 'very few',\n",
       " 'fancy little chic',\n",
       " 'somehow rated',\n",
       " 'best',\n",
       " 'best',\n",
       " 'single',\n",
       " 'most of the food',\n",
       " \"n't very memorable , but\",\n",
       " 'massive',\n",
       " 'open',\n",
       " 'more gangster',\n",
       " 'ever done',\n",
       " 'fish and',\n",
       " 'French',\n",
       " 'cheap and nasty and',\n",
       " 'possible to screw',\n",
       " 'basic',\n",
       " 'dish such',\n",
       " 'fish and',\n",
       " 'bread',\n",
       " 'literal',\n",
       " 'freshman',\n",
       " 'best Mexican',\n",
       " 'great',\n",
       " 'new',\n",
       " 'clean ,',\n",
       " 'super nice and',\n",
       " 'carne',\n",
       " 'free friendly',\n",
       " 'easy to sub anything',\n",
       " 'iffy',\n",
       " 'only seen',\n",
       " 'ASU',\n",
       " 'same',\n",
       " 'happily doing',\n",
       " 'okay',\n",
       " 'real Mexican',\n",
       " 'more',\n",
       " 'more professional',\n",
       " 'speak',\n",
       " 'open in the late nights',\n",
       " 'always welcoming',\n",
       " 'little disappointed',\n",
       " \"n't expecting\",\n",
       " 'ground',\n",
       " 'next',\n",
       " 'little',\n",
       " 'not just picked',\n",
       " 'el',\n",
       " 'always been',\n",
       " 'good but',\n",
       " 'still getting',\n",
       " 'extremely nice',\n",
       " 'only',\n",
       " 'too hot',\n",
       " 'hot',\n",
       " 'bad',\n",
       " 'mixed',\n",
       " 'fresh , but',\n",
       " 'hidden',\n",
       " 'quality fast mexican',\n",
       " 'chicken',\n",
       " 'great for late night',\n",
       " 'Good',\n",
       " 'very good',\n",
       " 'absolute best',\n",
       " 'ever had',\n",
       " 'Best',\n",
       " 'as big',\n",
       " 'tiny little',\n",
       " 'outside',\n",
       " 'pleasant',\n",
       " 'cramped',\n",
       " 'very tidy and',\n",
       " 'also pleasantly surprised',\n",
       " 'good',\n",
       " 'such',\n",
       " 'small',\n",
       " 'greasy gustatory',\n",
       " 'American',\n",
       " 'chicken',\n",
       " 'regular',\n",
       " 'few',\n",
       " 'different',\n",
       " 'sour',\n",
       " 'mega',\n",
       " 'curious',\n",
       " 'pretty good',\n",
       " 'so much',\n",
       " 'soggy',\n",
       " 'soggier over time',\n",
       " 'nice and fluffy and',\n",
       " 'very generous',\n",
       " 'other nice',\n",
       " 'open',\n",
       " 'late',\n",
       " 'so sick',\n",
       " 'next',\n",
       " 'soggy',\n",
       " 'hard to eat',\n",
       " 'very dry',\n",
       " 'awesome , open',\n",
       " 'big',\n",
       " 'cool ,']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjective_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82add923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "41c9dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "'This is the first document. And what?',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09a9f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbe8383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "tokens = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3edbe202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28339342, 0.        , 0.35944862, 0.2294314 , 0.35944862,\n",
       "        0.        , 0.28339342, 0.28339342, 0.1875752 , 0.2294314 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1875752 ,\n",
       "        0.28339342, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.1875752 , 0.        , 0.28339342, 0.        , 0.35944862],\n",
       "       [0.        , 0.        , 0.        , 0.45551258, 0.        ,\n",
       "        0.35682424, 0.        , 0.        , 0.18620569, 0.22775629,\n",
       "        0.        , 0.        , 0.35682424, 0.35682424, 0.18620569,\n",
       "        0.        , 0.35682424, 0.        , 0.        , 0.        ,\n",
       "        0.18620569, 0.35682424, 0.        , 0.        , 0.        ],\n",
       "       [0.28851197, 0.36594085, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.19096312, 0.2335753 ,\n",
       "        0.        , 0.36594085, 0.        , 0.        , 0.19096312,\n",
       "        0.        , 0.        , 0.36594085, 0.36594085, 0.36594085,\n",
       "        0.19096312, 0.        , 0.28851197, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.28293955, 0.        ,\n",
       "        0.        , 0.34948664, 0.34948664, 0.23132162, 0.        ,\n",
       "        0.44327948, 0.        , 0.        , 0.        , 0.23132162,\n",
       "        0.34948664, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23132162, 0.        , 0.        , 0.44327948, 0.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ae360ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X.toarray(), index=['Doc1','Doc2','Doc3','Doc4'], columns=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "106b09ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>and this</th>\n",
       "      <th>and what</th>\n",
       "      <th>document</th>\n",
       "      <th>document and</th>\n",
       "      <th>document is</th>\n",
       "      <th>first</th>\n",
       "      <th>first document</th>\n",
       "      <th>is</th>\n",
       "      <th>is the</th>\n",
       "      <th>...</th>\n",
       "      <th>the first</th>\n",
       "      <th>the second</th>\n",
       "      <th>the third</th>\n",
       "      <th>third</th>\n",
       "      <th>third one</th>\n",
       "      <th>this</th>\n",
       "      <th>this document</th>\n",
       "      <th>this is</th>\n",
       "      <th>this the</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.283393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359449</td>\n",
       "      <td>0.229431</td>\n",
       "      <td>0.359449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283393</td>\n",
       "      <td>0.283393</td>\n",
       "      <td>0.187575</td>\n",
       "      <td>0.229431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186206</td>\n",
       "      <td>0.227756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186206</td>\n",
       "      <td>0.356824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.288512</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>0.233575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349487</td>\n",
       "      <td>0.349487</td>\n",
       "      <td>0.231322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443279</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           and  and this  and what  document  document and  document is  \\\n",
       "Doc1  0.283393  0.000000  0.359449  0.229431      0.359449     0.000000   \n",
       "Doc2  0.000000  0.000000  0.000000  0.455513      0.000000     0.356824   \n",
       "Doc3  0.288512  0.365941  0.000000  0.000000      0.000000     0.000000   \n",
       "Doc4  0.000000  0.000000  0.000000  0.282940      0.000000     0.000000   \n",
       "\n",
       "         first  first document        is    is the  ...  the first  \\\n",
       "Doc1  0.283393        0.283393  0.187575  0.229431  ...   0.283393   \n",
       "Doc2  0.000000        0.000000  0.186206  0.227756  ...   0.000000   \n",
       "Doc3  0.000000        0.000000  0.190963  0.233575  ...   0.000000   \n",
       "Doc4  0.349487        0.349487  0.231322  0.000000  ...   0.349487   \n",
       "\n",
       "      the second  the third     third  third one      this  this document  \\\n",
       "Doc1    0.000000   0.000000  0.000000   0.000000  0.187575       0.000000   \n",
       "Doc2    0.356824   0.000000  0.000000   0.000000  0.186206       0.356824   \n",
       "Doc3    0.000000   0.365941  0.365941   0.365941  0.190963       0.000000   \n",
       "Doc4    0.000000   0.000000  0.000000   0.000000  0.231322       0.000000   \n",
       "\n",
       "       this is  this the      what  \n",
       "Doc1  0.283393  0.000000  0.359449  \n",
       "Doc2  0.000000  0.000000  0.000000  \n",
       "Doc3  0.288512  0.000000  0.000000  \n",
       "Doc4  0.000000  0.443279  0.000000  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5ada46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'and this',\n",
       " 'and what',\n",
       " 'document',\n",
       " 'document and',\n",
       " 'document is',\n",
       " 'first',\n",
       " 'first document',\n",
       " 'is',\n",
       " 'is the',\n",
       " 'is this',\n",
       " 'one',\n",
       " 'second',\n",
       " 'second document',\n",
       " 'the',\n",
       " 'the first',\n",
       " 'the second',\n",
       " 'the third',\n",
       " 'third',\n",
       " 'third one',\n",
       " 'this',\n",
       " 'this document',\n",
       " 'this is',\n",
       " 'this the',\n",
       " 'what']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e255bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc1f9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.22314355, 1.51082562, 1.        , 1.91629073,\n",
       "       1.91629073, 1.        , 1.91629073, 1.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9571bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0f7ee53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "         0.        , 0.38408524, 0.        , 0.38408524],\n",
       "        [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "         0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "        [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "         0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "        [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "         0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba19f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e171254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cba75597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.83258146, 2.4462871 , 3.02165125, 2.        , 3.83258146,\n",
       "       3.83258146, 2.        , 3.83258146, 2.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_ * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "324faf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.413592  , 0.26399042, 0.32608068, 0.21582946, 0.413592  ,\n",
       "        0.413592  , 0.21582946, 0.413592  , 0.21582946]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize((vectorizer.idf_ * 2).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11888f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
